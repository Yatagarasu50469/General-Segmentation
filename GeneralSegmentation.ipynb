{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#▀▀▀▀▀▀▀▀▀▀▀▀ ████████████████████████████████████████████ ▀▀▀▀▀▀▀▀▀▀▀▀\n",
    "#▀▀▀▀▀▀▀▀▀▀▀▀ ██ ▄▄ ██ ▄▄▄██ ▀██ ██ ▄▄▄██ ▄▄▀█ ▄▄▀██ █████ ▀▀▀▀▀▀▀▀▀▀▀▀\n",
    "#▀▀▀▀▀▀▀▀▀▀▀▀ ██ █▀▀██ ▄▄▄██ █ █ ██ ▄▄▄██ ▀▀▄█ ▀▀ ██ █████ ▀▀▀▀▀▀▀▀▀▀▀▀\n",
    "#▀▀▀▀▀▀▀▀▀▀▀▀ ██ ▀▀▄██ ▀▀▀██ ██▄ ██ ▀▀▀██ ██ █ ██ ██ ▀▀ ██ ▀▀▀▀▀▀▀▀▀▀▀▀\n",
    "#██████████████████████████████████████████████████████████████████████\n",
    "#█ ▄▄▄ ██ ▄▄▄██ ▄▄ ██ ▄▀▄ ██ ▄▄▄██ ▀██ █▄▄ ▄▄█ ▄▄▀█▄▄ ▄▄██ ▄▄▄ ██ ▀██ █\n",
    "#█▄▄▄▀▀██ ▄▄▄██ █▀▀██ █ █ ██ ▄▄▄██ █ █ ███ ███ ▀▀ ███ ████ ███ ██ █ █ █\n",
    "#█ ▀▀▀ ██ ▀▀▀██ ▀▀▄██ ███ ██ ▀▀▀██ ██▄ ███ ███ ██ ███ ████ ▀▀▀ ██ ██▄ █\n",
    "#██████████████████████████████████████████████████████████████████████"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa942e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING - There is not a sanity check for data file naming.\n",
    "#Please ensure there are matched, identically named pairs of inputs/outputs present in the DATA folders\n",
    "\n",
    "#====================================================================\n",
    "#CONFIGURATION\n",
    "#====================================================================\n",
    "\n",
    "#Is training of a model to be performed\n",
    "trainingModel = True\n",
    "\n",
    "#Is testing of a model to be performed\n",
    "testingModel = True\n",
    "\n",
    "#Should a random selection of the data (Ex. 0.1 or 10%) in TRAIN be moved to TEST (default: 0)\n",
    "#WARNING: Should only ever do this once, if you do not have a TEST dateset manually made available!\n",
    "testTrainRatio = 0\n",
    "\n",
    "#How should data be imported for model input 'GRAY' or 'RGB' (default: 'GRAY')\n",
    "inputMode = 'GRAY'\n",
    "\n",
    "#Which GPU(s) devices should be used for training; (Default: [-1], any/all available; CPU only: [])\n",
    "gpus = [-1]\n",
    "\n",
    "#Should training/validation data be entirely stored on GPU (default: True; improves training/validation performance, set to False if OOM occurs)\n",
    "storeOnDevice = True\n",
    "\n",
    "#How many filters should be used at the top layer of the network (default: 64)\n",
    "numStartFilters = 64\n",
    "\n",
    "#Which optimizer should be used ('AdamW', 'Adam', 'Nadam', 'SGD' or 'RMSProp')\n",
    "optimizer = 'AdamW'\n",
    "\n",
    "#What should the learning rate of the model optimizers be\n",
    "learningRate = 1e-5\n",
    "\n",
    "#Beta 1  parameter if applicable to the specified optimizer (default: 0.5)\n",
    "beta1 = 0.5\n",
    "\n",
    "#Beta 2  parameter if applicable to the specified optimizer (default: 0.5)\n",
    "beta2 = 0.999\n",
    "\n",
    "#What percentage of the training data should be used for training (default: 0.8)\n",
    "#1.0 or using only one input image will use training loss for early stopping criteria\n",
    "trainValRatio = 0.8\n",
    "\n",
    "#How many epochs should a model train for at maximum (default: 10000)\n",
    "numEpochs = 10000\n",
    "\n",
    "#How many epochs should the model training wait to see an improvement before terminating (default: 100)\n",
    "maxPatience = 100\n",
    "\n",
    "#How many epochs at minimum should be performed before starting to save the current best model and consider termination (default: 10)\n",
    "minimumEpochs = 10\n",
    "\n",
    "#What should the resized dimensions during augmentation be (default: (128, 128) for inputMode='GRAY'; (64, 64) for inputMode='RGB')\n",
    "#Recommend sticking to powers of 2 for GPU efficiency; shouldn't go above size of input images\n",
    "augSize = 64\n",
    "\n",
    "#Should the training data be augmented at the end of each epoch (default: True)\n",
    "augTrainData = True\n",
    "\n",
    "#Should the validation data be augmented at initialization (default: True)\n",
    "#Validation data needs to be consistent throughout training for early stopping criteria\n",
    "#Need to enable if input images are not a consistent size and batchsize_VAL=-1\n",
    "augValData = True\n",
    "\n",
    "#Training data batch size (default: 1)\n",
    "#Personal preference to stick with batch sizes of 1, which will train the slowest, but generally gives the best results\n",
    "#If batch normalization is introduced in the model, this needs to be at least 16!\n",
    "batchsize_TRN = 1\n",
    "\n",
    "#Validation data batch size (default: 1); -1 sets as total length of validation set, which can cause an OOM, depending on input dimensionality\n",
    "#Higher value here will decrease training time\n",
    "#For a given network, input dimensionality, and number of validation samples start with 1 and double until just below GPU VRAM cap\n",
    "#Ex. with default settings, dataset, and 24 GB VRAML: augSize=128 -> batchsize_VAL=256; augSize=64 -> batchsize_VAL=-1 \n",
    "#Note validation images must be a consistent size (naturally or through augmentation) for any value other than 1 to function\n",
    "batchsize_VAL = -1\n",
    "\n",
    "#RNG seed value to control run-to-run consistency, may slow performance, but should be used during development (-1 to disable)\n",
    "#WARNING - Cannot guarantee consistency between machines/hardware/software; if running benchmarks or ablation study, be as consistent as possible\n",
    "manualSeedValue = 0\n",
    "\n",
    "#Should visualizations of the training progression be generated (default: True)\n",
    "trainingProgressionVisuals = True\n",
    "\n",
    "#How often (epochs) should visualizations of the training progression be generated (default: 10)\n",
    "trainingVizSteps = 10\n",
    "\n",
    "#Input image extension\n",
    "fileExt = '.png'\n",
    "\n",
    "#Name for the trained model\n",
    "modelName = 'Model'\n",
    "\n",
    "#Should progress bars use ascii formatting (True in jupyter and False in terminal)\n",
    "asciiFlag = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b04a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#EXTERNAL\n",
    "#====================================================================\n",
    "\n",
    "#ENVIRONMENTAL VARIABLES\n",
    "#==================================================================\n",
    "\n",
    "#Setup deterministic behavior for CUDA; may change in future versions...\n",
    "#\"Set a debug environment variable CUBLAS_WORKSPACE_CONFIG to :16:8 (may limit overall performance) \n",
    "#or :4096:8 (will increase library footprint in GPU memory by approximately 24MiB).\"\n",
    "import os\n",
    "if manualSeedValue != -1: os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "    \n",
    "\n",
    "#IMPORTS\n",
    "#==================================================================\n",
    "\n",
    "import copy\n",
    "import cv2\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import multivolumefile\n",
    "import natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import py7zr\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as functional\n",
    "import torchvision.transforms as transforms\n",
    "import warnings\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.debugger import set_trace as Tracer\n",
    "from PIL import Image\n",
    "from sklearn.metrics import jaccard_score\n",
    "from torchvision.transforms import v2\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#LIBRARY AND WARNINGS SETUP\n",
    "#==================================================================\n",
    "\n",
    "#Specifically for notebook; expand cells to fill browser width\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:80% !important; }</style>\"))\n",
    "\n",
    "#Setup deterministic behavior for torch, numpy, and python (these alone do not affect CUDA-specific operations)\n",
    "if manualSeedValue != -1: \n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.manual_seed(manualSeedValue)\n",
    "    np.random.seed(manualSeedValue)\n",
    "    random.seed(manualSeedValue)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#DIRECTORIES\n",
    "#====================================================================\n",
    "\n",
    "dir_TrainingData = './DATA/TRAIN/'\n",
    "dir_TrainingData_Inputs = dir_TrainingData+ 'INPUTS/'\n",
    "dir_TrainingData_Labels = dir_TrainingData + 'LABELS/'\n",
    "\n",
    "dir_TestingData = './DATA/TEST/'\n",
    "dir_TestingData_Inputs = dir_TestingData + 'INPUTS/'\n",
    "dir_TestingData_Labels = dir_TestingData + 'LABELS/'\n",
    "\n",
    "dir_Results = './RESULTS/'\n",
    "\n",
    "dir_TrainingResults = dir_Results + 'TRAIN/'\n",
    "dir_TrainingResults_ModelProgression = dir_TrainingResults + 'Progression/'\n",
    "dir_TrainingResults_Model = dir_TrainingResults + modelName\n",
    "\n",
    "dir_TestingResults = dir_Results + 'TEST/'\n",
    "dir_TestingResults_Summary = dir_TestingResults + 'Summary/'\n",
    "dir_TestingResults_Predictions = dir_TestingResults + 'Predictions/'\n",
    "\n",
    "if os.path.exists(dir_Results): shutil.rmtree(dir_Results)\n",
    "\n",
    "os.makedirs(dir_TrainingResults)\n",
    "os.makedirs(dir_TrainingResults_ModelProgression)\n",
    "os.makedirs(dir_TrainingResults_Model)\n",
    "\n",
    "os.makedirs(dir_TestingResults)\n",
    "os.makedirs(dir_TestingResults_Summary)\n",
    "os.makedirs(dir_TestingResults_Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faa3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#COMPUTE\n",
    "#====================================================================\n",
    "\n",
    "#Note GPUs available/specified\n",
    "#If multiple/parallel GPU acceleration is needed, then adopt DDP using Ray\n",
    "if not torch.cuda.is_available(): gpus = []\n",
    "numGPUs = len(gpus)\n",
    "if (numGPUs > 0) and (gpus[0] == -1): gpus = [*range(torch.cuda.device_count())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#UTILITY CLASSES/METHODS\n",
    "#==================================================================\n",
    "\n",
    "#Visualize/save an image without borders/axes\n",
    "def visualizeBorderless(image, saveLocation, cmap='gray', vmin=None, vmax=None):\n",
    "    if type(cmap) == str: cmap = plt.get_cmap(cmap)\n",
    "    if vmin==None: vmin=np.nanmin(image)\n",
    "    if vmax==None: vmax=np.nanmax(image)\n",
    "    Image.fromarray(np.uint8(cmap(((np.clip(image, vmin, vmax)-vmin)/(vmax-vmin)))*255)).save(saveLocation)\n",
    "\n",
    "#Visualize/save a simple data plot\n",
    "def basicPlot(xData, yData, saveLocation, xLabel='', yLabel=''):\n",
    "    font = {'size' : 18}\n",
    "    plt.rc('font', **font)\n",
    "    f = plt.figure(figsize=(20,8))\n",
    "    ax1 = f.add_subplot(1,1,1)    \n",
    "    ax1.plot(xData, yData, color='black')\n",
    "    ax1.set_xlabel(xLabel)\n",
    "    ax1.set_ylabel(yLabel)\n",
    "    plt.savefig(saveLocation)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff32268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#NETWORK CLASSES/METHODS\n",
    "#====================================================================\n",
    "\n",
    "#Slighly modified, but still quite basic U-Net architecture\n",
    "#Uses leaky relu activations throughout to better propogate loss during backpropogation\n",
    "#Upsampling swaps in nearest-neightbor resizing in place of convolutional transposition to remove checkerboard artifacts\n",
    "#Augmentation is performed on trainingdata after every epoch to maximize data variance, consider adding additional transforms\n",
    "#Bias disabled for efficiency; shouldn't make a noticable difference here\n",
    "\n",
    "#Downsampling convolutional block\n",
    "class Conv_Dn(nn.Module):\n",
    "    def __init__(self, numIn, numOut):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) \n",
    "        self.conv0 = nn.Conv2d(in_channels=numIn, out_channels=numOut, kernel_size=3, stride=1, padding='same', bias=False)\n",
    "        self.conv1 = nn.Conv2d(in_channels=numOut, out_channels=numOut, kernel_size=3, stride=1, padding='same', bias=False)\n",
    "        nn.init.normal_(self.conv0.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.act(self.conv0(data))\n",
    "        return self.act(self.conv1(data))\n",
    "\n",
    "#Upsampling convolutional block\n",
    "class Conv_Up(nn.Module):\n",
    "    def __init__(self, numIn, numOut):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv0 = nn.Conv2d(in_channels=numIn, out_channels=numIn, kernel_size=3, stride=1, padding='same', bias=False)\n",
    "        self.conv1 = nn.Conv2d(in_channels=numIn+numOut, out_channels=numOut, kernel_size=3, stride=1, padding='same', bias=False)\n",
    "        nn.init.normal_(self.conv0.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, data, skip):\n",
    "        data = self.act(self.conv0(functional.interpolate(data, size=skip.size()[2:], mode='nearest')))\n",
    "        return self.act(self.conv1(torch.cat([data, skip], 1)))\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, numFilt, numChan):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.convDn0 = Conv_Dn(numChan, numFilt)\n",
    "        self.convDn1 = Conv_Dn(numFilt, numFilt*2)\n",
    "        self.convDn2 = Conv_Dn(numFilt*2, numFilt*4)\n",
    "        self.convDn3 = Conv_Dn(numFilt*4, numFilt*8)\n",
    "        self.convDn4 = Conv_Dn(numFilt*8, numFilt*16)\n",
    "        \n",
    "        self.convUp3 = Conv_Up(numFilt*16, numFilt*8)\n",
    "        self.convUp2 = Conv_Up(numFilt*8, numFilt*4)\n",
    "        self.convUp1 = Conv_Up(numFilt*4, numFilt*2)\n",
    "        self.convUp0 = Conv_Up(numFilt*2, numFilt)\n",
    "        \n",
    "        self.convOut = nn.Conv2d(in_channels=numFilt, out_channels=1, kernel_size=3, stride=1, padding='same', bias=False)\n",
    "        nn.init.normal_(self.convOut.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        convDn0 = self.convDn0(data)\n",
    "        convDn1 = self.convDn1(self.pool(convDn0))\n",
    "        convDn2 = self.convDn2(self.pool(convDn1))\n",
    "        convDn3 = self.convDn3(self.pool(convDn2))\n",
    "        convDn4 = self.convDn4(self.pool(convDn3))\n",
    "        \n",
    "        convUp3 = self.convUp3(convDn4, convDn3)\n",
    "        convUp2 = self.convUp2(convDn3, convDn2)\n",
    "        convUp1 = self.convUp1(convDn2, convDn1)\n",
    "        convUp0 = self.convUp0(convDn1, convDn0)\n",
    "        return self.convOut(convUp0)\n",
    "    \n",
    "#Perform augmentation and setup for DLADS data processing\n",
    "class DataPreprocessing(Dataset):\n",
    "    def __init__(self, inputs, labels, device, augmentFlag, trainDataFlag):\n",
    "        super().__init__()\n",
    "        self.noAugmentFlag = not augmentFlag\n",
    "        self.trainDataFlag = trainDataFlag\n",
    "        \n",
    "        if storeOnDevice:\n",
    "            self.data_Inputs = [torch.from_numpy(item).float().to(device) for item in inputs]\n",
    "            self.data_Labels = [torch.from_numpy(item).float().to(device) for item in labels]\n",
    "        else: \n",
    "            self.data_Inputs = [torch.from_numpy(item).float() for item in inputs]\n",
    "            self.data_Labels = [torch.from_numpy(item).float() for item in labels]\n",
    "        self.channelSplit = [self.data_Inputs[0].size()[0]]\n",
    "        \n",
    "        if augmentFlag: \n",
    "            self.transform = transforms.Compose([\n",
    "                v2.RandomResizedCrop(size=(augSize, augSize), scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0), antialias=True), #https://arxiv.org/pdf/1409.4842.pdf\n",
    "                v2.RandomHorizontalFlip(p=0.5),\n",
    "                v2.RandomVerticalFlip(p=0.5)\n",
    "            ])\n",
    "            \n",
    "        #Validation data should only be augmented at initialization for stable execution of early stopping criteria\n",
    "        if augmentFlag and not trainDataFlag:\n",
    "            for index in range(0, len(self.data_Inputs)):\n",
    "                self.data_Inputs[index], self.data_Labels[index] = torch.tensor_split(self.transform(torch.cat([self.data_Inputs[index], self.data_Labels[index]], 0)), self.channelSplit, 0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.noAugmentFlag or not self.trainDataFlag: return self.data_Inputs[index], self.data_Labels[index]\n",
    "        return torch.tensor_split(self.transform(torch.cat([self.data_Inputs[index], self.data_Labels[index]], 0)), self.channelSplit, 0)\n",
    "               \n",
    "    def __len__(self):\n",
    "        return len(self.data_Inputs)\n",
    "\n",
    "#Define GeneralSegmentation network\n",
    "class GeneralSegmentation:\n",
    "    def __init__(self, trainFlag, local_gpus):\n",
    "    \n",
    "        #Create model\n",
    "        if inputMode == 'GRAY': self.model = Model(numStartFilters, 1)\n",
    "        elif inputMode == 'RGB': self.model = Model(numStartFilters, 3)\n",
    "    \n",
    "        #If not training, load parameters (before potential parallelization on multiple GPUs) and setup for inferencing\n",
    "        if not trainFlag: \n",
    "            with multivolumefile.open(dir_TrainingResults_Model + os.path.sep + modelName + '.7z', mode='rb') as modelArchive:\n",
    "                with py7zr.SevenZipFile(modelArchive, 'r') as archive:\n",
    "                    archive.extract(dir_TrainingResults)\n",
    "            _ = self.model.load_state_dict(torch.load(dir_TrainingResults_Model + '.pt'))\n",
    "            _ = self.model.train(False)\n",
    "            os.remove(dir_TrainingResults_Model + '.pt')\n",
    "            \n",
    "        #Configure CPU/GPU computation environment\n",
    "        self.device = torch.device(f\"cuda:{local_gpus[0]}\" if len(local_gpus) > 0 else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        #If training, setup optimizers, load the data, and perform training\n",
    "        if trainFlag:\n",
    "            if optimizer == 'AdamW': self.opt = optim.AdamW(self.model.parameters(), lr=learningRate, betas=(beta1, beta2))\n",
    "            elif optimizer == 'Adam': self.opt = optim.Adam(self.model.parameters(), lr=learningRate, betas=(beta1, beta2))\n",
    "            elif optimizer == 'Nadam': self.opt = optim.NAdam(self.model.parameters(), lr=learningRate, betas=(beta1, beta2))\n",
    "            elif optimizer == 'SGD': self.opt = optim.SGD(self.model.parameters(), lr=learningRate)\n",
    "            elif optimizer == 'RMSProp': self.opt = optim.RMSprop(self.model.parameters(), lr=learningRate)\n",
    "            self.loadData()\n",
    "            self.train()\n",
    "            \n",
    "    def loadData(self):\n",
    "    \n",
    "        #Accumulate input files; sorting by name to ensure consistant order behavior\n",
    "        filenames_Inputs = natsort.natsorted(glob.glob(dir_TrainingData_Inputs+'*'+fileExt), reverse=False)\n",
    "        filenames_Labels = natsort.natsorted(glob.glob(dir_TrainingData_Labels+'*'+fileExt), reverse=False)\n",
    "        numInputs = len(filenames_Inputs)\n",
    "        if numInputs != len(filenames_Labels): sys.exit('Error - The number of inputData and label files for training do not match')\n",
    "        \n",
    "        #Find index to split data into training/validation sets\n",
    "        trainValSplit = int(trainValRatio*numInputs)\n",
    "    \n",
    "        #If there is not going to be a validation set then indicate such, otherwise setup needed variables\n",
    "        if trainValSplit == numInputs:\n",
    "            self.valFlag = False\n",
    "        else:\n",
    "            self.valFlag = True\n",
    "            vizSampleIndices = [numInputs-14, numInputs-4]\n",
    "            self.numViz = len(vizSampleIndices)\n",
    "            inputs_VAL, labels_VAL = [], []\n",
    "            self.inputs_VIZ_NET, self.inputs_VIZ, self.labels_VIZ = [], [], []\n",
    "        \n",
    "        #Extract and prepare data\n",
    "        inputs_TRN, labels_TRN = [], []\n",
    "        for index in tqdm(range(0, numInputs), desc = 'Loading TRN Data', leave=True, ascii=asciiFlag):\n",
    "            \n",
    "            #Load inputs and labels, arranging dimensions to be [C, H, W]\n",
    "            if inputMode=='GRAY': inputData = np.expand_dims(cv2.cvtColor(cv2.imread(filenames_Inputs[index]), cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0, 0)\n",
    "            elif inputMode=='RGB': inputData = np.moveaxis(cv2.cvtColor(cv2.imread(filenames_Inputs[index]), cv2.COLOR_BGR2RGB).astype(np.float32)/255.0, -1, 0)\n",
    "            label = cv2.cvtColor(cv2.imread(filenames_Labels[index]), cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0\n",
    "            \n",
    "            #Handle any validation data intended to be shown in model progression images\n",
    "            if self.valFlag and (index in vizSampleIndices):\n",
    "                \n",
    "                #Setup input data for processing by the network, arranging dimensions to be [B=1, C, H, W]\n",
    "                if storeOnDevice: self.inputs_VIZ_NET.append(torch.from_numpy(np.expand_dims(inputData, 0)).float().to(self.device))\n",
    "                else: self.inputs_VIZ_NET.append(torch.from_numpy(np.expand_dims(inputData, 0)).float())\n",
    "                \n",
    "                #Setup input data for visualization, arranging dimension to be [H, W, C (if applicable)]\n",
    "                if inputMode=='GRAY': self.inputs_VIZ.append(inputData[0])\n",
    "                elif inputMode=='RGB': self.inputs_VIZ.append(np.moveaxis(inputData, 0, -1))\n",
    "                self.labels_VIZ.append(label)\n",
    "            \n",
    "            #Store data into the appropriate dataset; training or validation\n",
    "            label = np.expand_dims(label, 0)\n",
    "            if index <= trainValSplit:\n",
    "                inputs_TRN.append(inputData)\n",
    "                labels_TRN.append(label)\n",
    "            else:\n",
    "                inputs_VAL.append(inputData)\n",
    "                labels_VAL.append(label)\n",
    "            \n",
    "        #Setup data handler for training dataset\n",
    "        data_TRN = DataPreprocessing(inputs_TRN, labels_TRN, self.device, augTrainData, True)\n",
    "        self.dataloader_TRN = DataLoader(data_TRN, batch_size=batchsize_TRN, num_workers=0, shuffle=True)\n",
    "        self.numTRN = len(self.dataloader_TRN)\n",
    "        \n",
    "        #Setup data handler for validation dataset\n",
    "        if self.valFlag:\n",
    "            data_VAL = DataPreprocessing(inputs_VAL, labels_VAL, self.device, augValData, False)\n",
    "            if batchsize_VAL == -1: self.dataloader_VAL = DataLoader(data_VAL, batch_size=len(inputs_VAL), num_workers=0, shuffle=False)\n",
    "            else: self.dataloader_VAL = DataLoader(data_VAL, batch_size=batchsize_VAL, num_workers=0, shuffle=False)\n",
    "            self.numVAL = len(self.dataloader_VAL)\n",
    "                \n",
    "    #Produce/save visualizations after a training epoch\n",
    "    def visualizeTraining(self, epoch):\n",
    "        \n",
    "        #Setup blank canvas\n",
    "        if self.valFlag: f = plt.figure(figsize=(24,15))\n",
    "        else: f = plt.figure(figsize=(24,5))\n",
    "        f.subplots_adjust(top = 0.90)\n",
    "        f.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        \n",
    "        #Visualize training/validation loss plots\n",
    "        if self.valFlag: ax = plt.subplot2grid((3,1), (0,0))\n",
    "        else: ax = plt.subplot2grid((1,1), (0,0))\n",
    "        ax.plot(self.loss_Trn, label='Training')\n",
    "        if self.valFlag: ax.plot(self.loss_Val, label='Validation')\n",
    "        ax.legend(loc='upper right', fontsize=14)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        #Process and visualize each of the validation samples intended for illustration across training progression\n",
    "        if self.valFlag: \n",
    "            for vizSampleNum in range(0, self.numViz): \n",
    "            \n",
    "                if not storeOnDevice: inputData = self.inputs_VIZ_NET[vizSampleNum].to(self.device)\n",
    "                else: inputData = self.inputs_VIZ_NET[vizSampleNum]\n",
    "                input_VIZ = self.inputs_VIZ[vizSampleNum]\n",
    "                label_REAL = self.labels_VIZ[vizSampleNum]\n",
    "                \n",
    "                label_PRED, label_PRED_Processed = self.inference(inputData, False)\n",
    "                score_Jaccard = jaccard_score(label_REAL.astype(int), label_PRED_Processed, pos_label=1, average='micro', zero_division=1.0)\n",
    "                \n",
    "                ax = plt.subplot2grid((3,4), (vizSampleNum+1,0))\n",
    "                im = ax.imshow(input_VIZ, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "                ax.set_title('Input', fontsize=15, fontweight='bold')\n",
    "                cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "                cbar.formatter.set_powerlimits((0, 0))\n",
    "                \n",
    "                ax = plt.subplot2grid((3,4), (vizSampleNum+1,1))\n",
    "                im = ax.imshow(label_REAL, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "                ax.set_title('Ground-Truth', fontsize=15, fontweight='bold')\n",
    "                cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "                cbar.formatter.set_powerlimits((0, 0))\n",
    "                \n",
    "                ax = plt.subplot2grid((3,4), (vizSampleNum+1,2))\n",
    "                im = ax.imshow(label_PRED, aspect='auto', cmap='gray', interpolation='none')\n",
    "                plotTitle = 'PRED'\n",
    "                ax.set_title(plotTitle, fontsize=15, fontweight='bold')\n",
    "                cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "                cbar.formatter.set_powerlimits((0, 0))\n",
    "                \n",
    "                ax = plt.subplot2grid((3,4), (vizSampleNum+1,3))\n",
    "                im = ax.imshow(label_PRED_Processed, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "                plotTitle = 'PRED>=0.5 - Jaccard: ' + '{:.6f}'.format(round(score_Jaccard, 6))\n",
    "                ax.set_title(plotTitle, fontsize=15, fontweight='bold')\n",
    "                cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "                cbar.formatter.set_powerlimits((0, 0))\n",
    "            \n",
    "            plotTitle = 'Epoch: '+str(epoch)+'     Patience: '+str(self.patience)+'/'+str(maxPatience)\n",
    "            plotTitle += '\\nBest Loss: '+ '{:.6f}'.format(round(self.bestLoss, 6)) +' at Epoch: '+str(self.bestEpoch)\n",
    "            plotTitle += '\\nLoss - TRN: ' + '{:.6f}'.format(round(self.loss_Trn[-1], 6))\n",
    "            plotTitle += '     VAL: ' + '{:.6f}'.format(round(self.loss_Val[-1], 6))\n",
    "            plt.suptitle(plotTitle, fontsize=20, fontweight='bold')\n",
    "            \n",
    "            #Save resulting plot\n",
    "            f.savefig(dir_TrainingResults_ModelProgression + 'epoch_' +str(epoch) + '.tiff', bbox_inches='tight')\n",
    "            plt.close(f)\n",
    "        \n",
    "    def computeLoss(self, data, label, trainFlag=False):\n",
    "        \n",
    "        #Zero network gradients\n",
    "        if trainFlag: self.model.zero_grad()\n",
    "        \n",
    "        #Compute MAE\n",
    "        if not storeOnDevice: data, label = data.to(self.device), label.to(self.device)\n",
    "        loss = torch.mean(torch.abs(self.model(data)-label))\n",
    "        \n",
    "        #Compute loss gradients and update network parameters\n",
    "        if trainFlag:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "        \n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        #Setup storage for losses\n",
    "        self.loss_Trn, self.loss_Val = [], []\n",
    "\n",
    "        #Setup variables for early stopping critera\n",
    "        bestModel, self.bestLoss, self.bestEpoch, self.patience, endTraining = None, np.inf, -1, 0, False\n",
    "\n",
    "        #Create progress bar\n",
    "        trainingBar = tqdm(range(numEpochs), desc=\"Epochs\", leave=True, ascii=asciiFlag)\n",
    "        \n",
    "        #Perform model training\n",
    "        t0 = time.time()\n",
    "        for epoch in trainingBar:\n",
    "            \n",
    "            #Compute losses over the training dataset\n",
    "            _ = self.model.train(True)\n",
    "            self.loss_Trn.append(np.mean([self.computeLoss(data, label, True) for data, label in tqdm(self.dataloader_TRN, total=self.numTRN, desc='TRN Batches', leave=False, ascii=asciiFlag)]))\n",
    "            \n",
    "            #Compute losses over the validation dataset\n",
    "            _ = self.model.train(False)\n",
    "            if self.valFlag: \n",
    "                with torch.inference_mode(): \n",
    "                    self.loss_Val.append(np.mean([self.computeLoss(data, label, False) for data, label in tqdm(self.dataloader_VAL, total=self.numVAL, desc='VAL Batches', leave=False, ascii=asciiFlag)]))\n",
    "            \n",
    "            #If applicable: update best model parameters or increase patience\n",
    "            if (epoch >= minimumEpochs):\n",
    "                \n",
    "                if self.valFlag: currLoss = self.loss_Val[-1]\n",
    "                else: currLoss = self.loss_Trn[-1]\n",
    "                \n",
    "                if (currLoss <= self.bestLoss): bestModel, self.bestLoss, self.bestEpoch, self.patience = copy.deepcopy(self.model.state_dict()), currLoss, epoch, 0\n",
    "                else: self.patience += 1\n",
    "            \n",
    "            #Update progress bar with epoch data\n",
    "            progBarString = \"PAT: \" + str(self.patience) + \"/\" + str(maxPatience)\n",
    "            progBarString += \", LOSS -\" \n",
    "            progBarString += \" TRN: \" + '{:.6f}'.format(round(self.loss_Trn[-1], 6))\n",
    "            if self.valFlag: progBarString += \", VAL: \" + '{:.6f}'.format(round(self.loss_Val[-1], 6))\n",
    "            trainingBar.set_postfix_str(progBarString)\n",
    "            trainingBar.refresh()\n",
    "            \n",
    "            #Exit training if early stopping criteria is triggered\n",
    "            if self.patience >= maxPatience: endTraining = True\n",
    "            \n",
    "            #Perform visualization(s) if applicable\n",
    "            if trainingProgressionVisuals and ((epoch == 0) or (epoch % trainingVizSteps == 0) or endTraining or (self.bestEpoch == epoch)): self.visualizeTraining(epoch)\n",
    "        \n",
    "            #If training should be terminated, exit the loop\n",
    "            if endTraining: break\n",
    "        \n",
    "        t1 = time.time()\n",
    "        trainingTime = datetime.timedelta(seconds=(t1-t0))\n",
    "        \n",
    "        lines = ['Model Training Time: ' + str(trainingTime)]\n",
    "        with open(dir_TrainingResults + 'trainingTime.txt', 'w') as f:\n",
    "            for line in lines: _ = f.write(line+'\\n')\n",
    "        print(lines[0])\n",
    "        \n",
    "        #Strip out any parallel 'module' references from the model definition\n",
    "        bestModel = {key.replace(\"module.\", \"\"): value for key, value in bestModel.items()}\n",
    "        \n",
    "        #Store the model across multiple 100 Mb files to bypass Github file size limits\n",
    "        torch.save(bestModel, dir_TrainingResults_Model + '.pt')\n",
    "        if os.path.exists(dir_TrainingResults_Model): shutil.rmtree(dir_TrainingResults_Model)\n",
    "        os.makedirs(dir_TrainingResults_Model)\n",
    "        with multivolumefile.open(dir_TrainingResults_Model + os.path.sep + modelName + '.7z', mode='wb', volume=104857600) as modelArchive:\n",
    "            with py7zr.SevenZipFile(modelArchive, 'w') as archive:\n",
    "                archive.writeall(dir_TrainingResults_Model + '.pt', modelName + '.pt')\n",
    "        os.remove(dir_TrainingResults_Model + '.pt')\n",
    "        \n",
    "        #Save training history\n",
    "        history = np.vstack([np.array(range(0, epoch+1)), self.loss_Trn])\n",
    "        if self.valFlag: history = np.vstack([history, self.loss_Val])\n",
    "        pd.DataFrame(history.T, columns=['Epoch','Loss_TRN', 'Loss_VAL']).to_csv(dir_TrainingResults+'trainingHistory.csv', index=False)\n",
    "    \n",
    "    def inference(self, inputData, transferFlag):\n",
    "        if transferFlag: inputData = inputData.to(self.device)\n",
    "        with torch.inference_mode(): label_PRED = self.model(inputData).detach().cpu().numpy()[0, 0]\n",
    "        label_PRED_Processed = (label_PRED>=0.5).astype(int)\n",
    "        return label_PRED, label_PRED_Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767cb53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#MAIN PROGRAM\n",
    "#====================================================================\n",
    "\n",
    "#If a TEST set has to be split out from the inputs stored in TRAIN, do so before importing and training a model\n",
    "if testTrainRatio > 0:\n",
    "    \n",
    "    #Verify the TEST directories are empty before proceeding\n",
    "    if len(glob.glob(dir_TestingData_Inputs+'*'+fileExt)) > 0 or len(glob.glob(dir_TestingData_Labels+'*'+fileExt)) > 0: \n",
    "        print(\"\\nWarning - TEST directory already contains files. Either disable testTrainSplit, which should only ever be run once, or clear the TEST/INPUTS and TEST/LABELS directories. Proceeding under the assumption that testing should use only the files that are already present in the DATA/TEST/ directories.\\n\")\n",
    "    else:\n",
    "        #Reset deterministic behavior for torch, numpy, and python (these alone do not affect CUDA-specific operations)\n",
    "        if manualSeedValue != -1: \n",
    "            torch.use_deterministic_algorithms(True)\n",
    "            torch.manual_seed(manualSeedValue)\n",
    "            np.random.seed(manualSeedValue)\n",
    "            random.seed(manualSeedValue)\n",
    "\n",
    "        #Accumulate input files; sorting by name to ensure consistant order behavior\n",
    "        filenames_Inputs = natsort.natsorted(glob.glob(dir_TrainingData_Inputs+'*'+fileExt), reverse=False)\n",
    "        filenames_Labels = natsort.natsorted(glob.glob(dir_TrainingData_Labels+'*'+fileExt), reverse=False)\n",
    "        numInputs = len(filenames_Inputs)\n",
    "\n",
    "        #Find index to split data into training/validation sets\n",
    "        testTrainSplit = int(testTrainRatio*numInputs)\n",
    "\n",
    "        #Move random selection of files to the TEST directory\n",
    "        filenames = list(zip(filenames_Inputs, filenames_Labels))\n",
    "        random.shuffle(filenames)\n",
    "        filenames_Inputs, filenames_Labels = zip(*filenames)\n",
    "        filenames_Inputs, filenames_Labels = filenames_Inputs[-testTrainSplit:], filenames_Labels[-testTrainSplit:]\n",
    "        _ = [shutil.move(filename, dir_TestingData_Inputs+os.path.basename(filename)) for filename in filenames_Inputs]\n",
    "        _ = [shutil.move(filename, dir_TestingData_Labels+os.path.basename(filename)) for filename in filenames_Labels]\n",
    "\n",
    "#Train a new model\n",
    "if trainingModel: \n",
    "    \n",
    "    #Reset deterministic behavior for torch, numpy, and python (these alone do not affect CUDA-specific operations)\n",
    "    if manualSeedValue != -1: \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        torch.manual_seed(manualSeedValue)\n",
    "        np.random.seed(manualSeedValue)\n",
    "        random.seed(manualSeedValue)\n",
    "        \n",
    "    #Create a new model; automatically starts training \n",
    "    network = GeneralSegmentation(True, gpus)\n",
    "\n",
    "#Test a trained model\n",
    "if testingModel: \n",
    "    \n",
    "    #Reset deterministic behavior for torch, numpy, and python (these alone do not affect CUDA-specific operations)\n",
    "    if manualSeedValue != -1: \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        torch.manual_seed(manualSeedValue)\n",
    "        np.random.seed(manualSeedValue)\n",
    "        random.seed(manualSeedValue)\n",
    "        \n",
    "    #Load the existing model \n",
    "    network = GeneralSegmentation(False, gpus)\n",
    "    \n",
    "    #Accumulate input files; sorting by name to ensure consistant order behavior\n",
    "    filenames_Inputs = natsort.natsorted(glob.glob(dir_TestingData_Inputs+'*'+fileExt), reverse=False)\n",
    "    filenames_Labels = natsort.natsorted(glob.glob(dir_TestingData_Labels+'*'+fileExt), reverse=False)\n",
    "    numInputs = len(filenames_Inputs)\n",
    "    if numInputs != len(filenames_Labels): sys.exit('Error - The number of inputData and label files for training do not match')\n",
    "    \n",
    "    #Load in the testing dataset\n",
    "    inputs_TST_NET, inputs_TST, labels_TST, inputs_Names = [], [], [], []\n",
    "    for index in tqdm(range(0, numInputs), desc = 'Loading TST Data', leave=True, ascii=asciiFlag):\n",
    "        inputs_Names.append(os.path.splitext(os.path.basename(filenames_Inputs[index]))[0])\n",
    "        if inputMode=='GRAY': inputData = np.expand_dims(cv2.cvtColor(cv2.imread(filenames_Inputs[index]), cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0, 0)\n",
    "        elif inputMode=='RGB': inputData = np.moveaxis(cv2.cvtColor(cv2.imread(filenames_Inputs[index]), cv2.COLOR_BGR2RGB).astype(np.float32)/255.0, -1, 0)\n",
    "        label = cv2.cvtColor(cv2.imread(filenames_Labels[index]), cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0\n",
    "        inputs_TST_NET.append(torch.from_numpy(np.expand_dims(inputData, 0)).float())\n",
    "        labels_TST.append(label)\n",
    "        \n",
    "        #Setup input data for visualization, arranging dimension to be [H, W, C (if applicable)]\n",
    "        if inputMode=='GRAY': inputs_TST.append(inputData[0])\n",
    "        elif inputMode=='RGB': inputs_TST.append(np.moveaxis(inputData, 0, -1))\n",
    "    \n",
    "    #Inference, evaluate, and visualize the testing dataset/results\n",
    "    scores_Jaccard = []\n",
    "    for index in tqdm(range(0, numInputs), desc = 'Testing', leave=True, ascii=asciiFlag):\n",
    "\n",
    "        input_VIZ = inputs_TST[index]\n",
    "        label_REAL = labels_TST[index]\n",
    "        label_PRED, label_PRED_Processed = network.inference(inputs_TST_NET[index], True)\n",
    "        score_Jaccard = jaccard_score(label_REAL.astype(int), label_PRED_Processed, pos_label=1, average='micro', zero_division=1.0)\n",
    "        scores_Jaccard.append(score_Jaccard)\n",
    "\n",
    "        #Setup blank canvas\n",
    "        f = plt.figure(figsize=(12,2.5))\n",
    "        f.subplots_adjust(top = 0.75)\n",
    "        f.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "        ax = plt.subplot2grid((1,4), (0,0))\n",
    "        im = ax.imshow(input_VIZ, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "        ax.set_title('Input', fontsize=10, fontweight='bold')\n",
    "        cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "        ax = plt.subplot2grid((1,4), (0,1))\n",
    "        im = ax.imshow(label_REAL, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "        ax.set_title('Ground-Truth', fontsize=10, fontweight='bold')\n",
    "        cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "        ax = plt.subplot2grid((1,4), (0,2))\n",
    "        im = ax.imshow(label_PRED, aspect='auto', cmap='gray', interpolation='none')\n",
    "        plotTitle = 'PRED'\n",
    "        ax.set_title(plotTitle, fontsize=10, fontweight='bold')\n",
    "        cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "        ax = plt.subplot2grid((1,4), (0,3))\n",
    "        im = ax.imshow(label_PRED_Processed, aspect='auto', cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
    "        plotTitle = 'PRED>=0.5'\n",
    "        ax.set_title(plotTitle, fontsize=10, fontweight='bold')\n",
    "        cbar = f.colorbar(im, ax=ax, orientation='vertical', pad=0.01)\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "        plotTitle = inputs_Names[index]\n",
    "        plotTitle += '\\nJaccard Score: ' + '{:.6f}'.format(round(score_Jaccard, 6))\n",
    "        plt.suptitle(plotTitle, fontsize=10, fontweight='bold')\n",
    "\n",
    "        f.savefig(dir_TestingResults_Summary + inputs_Names[index] + '_summary.tiff', bbox_inches='tight')\n",
    "        plt.close(f)\n",
    "\n",
    "        visualizeBorderless(label_PRED_Processed, dir_TestingResults_Predictions + inputs_Names[index] + '_prediction.tiff', cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    lines = ['Jaccard Score: ' + str(np.mean(scores_Jaccard)) + ' +/- ' + str(np.std(scores_Jaccard))]\n",
    "    with open(dir_TestingResults + 'dataPrintout.csv', 'w') as f:\n",
    "        for line in lines: \n",
    "            _ = f.write(line+'\\n')\n",
    "            print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e994f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
